{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Hull Tactical — Market Prediction: Strong baseline notebook\n",
        "What this notebook does\n",
        "- Loads local train/test (no internet)\n",
        "- Time-series-safe preprocessing and light feature engineering\n",
        "- Walk-forward (expanding window) cross-validation with LightGBM\n",
        "- Volatility-aware allocation mapping in [0, 2] with a practical risk cap\n",
        "- Diagnostics: CV RMSE, feature importances, simple backtest and Sharpe stats\n",
        "- Trains final ensemble and writes submission.csv with columns ['date_id','allocation']\n",
        "\n",
        "Notes & cautions\n",
        "- This is a reproducible, efficient baseline designed to run < 1 hour in Kaggle.\n",
        "- To reach top leaderboard: engineer better features (macro, cross-asset, seasonalities),\n",
        "  robust stacking/ensembling, volatility forecasting, and careful walk-forward tuning.\n",
        "\"\"\"\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import lightgbm as lgb\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "TRAIN_PATH = 'train.csv'\n",
        "TEST_PATH  = 'test.csv'\n",
        "EVAL_DIR   = 'kaggle_evaluation'  # present in competition env; not required here\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# 1) Load data\n",
        "LOGGER.info('Loading data...')\n",
        "train = pd.read_csv(TRAIN_PATH)\n",
        "test  = pd.read_csv(TEST_PATH)\n",
        "\n",
        "# Sort by time to ensure proper temporal order\n",
        "if 'date_id' in train.columns:\n",
        "    train = train.sort_values('date_id').reset_index(drop=True)\n",
        "if 'date_id' in test.columns:\n",
        "    test = test.sort_values('date_id').reset_index(drop=True)\n",
        "\n",
        "LOGGER.info(f'Train shape: {train.shape}')\n",
        "LOGGER.info(f'Test  shape: {test.shape}')\n",
        "\n",
        "# 2) Target selection (excess returns preferred). We keep a realized return series for backtest if possible.\n",
        "# Priority: use 'market_forward_excess_returns' if provided; otherwise compute from 'forward_returns' - 'risk_free_rate'.\n",
        "if 'market_forward_excess_returns' in train.columns:\n",
        "    TARGET = 'market_forward_excess_returns'\n",
        "    LOGGER.info('Using TARGET = market_forward_excess_returns')\n",
        "else:\n",
        "    if 'forward_returns' in train.columns and 'risk_free_rate' in train.columns:\n",
        "        train['market_forward_excess_returns'] = train['forward_returns'] - train['risk_free_rate']\n",
        "        TARGET = 'market_forward_excess_returns'\n",
        "        LOGGER.info('Computed TARGET = forward_returns - risk_free_rate')\n",
        "    else:\n",
        "        raise ValueError('Target not found: need market_forward_excess_returns or (forward_returns and risk_free_rate).')\n",
        "\n",
        "# Realized returns for toy backtest\n",
        "if 'forward_returns' in train.columns:\n",
        "    realized_returns = train['forward_returns'].copy()\n",
        "elif 'market_forward_excess_returns' in train.columns and 'risk_free_rate' in train.columns:\n",
        "    realized_returns = train['market_forward_excess_returns'] + train['risk_free_rate']\n",
        "elif 'market_forward_excess_returns' in train.columns:\n",
        "    realized_returns = train['market_forward_excess_returns'].copy()\n",
        "else:\n",
        "    realized_returns = None\n",
        "\n",
        "# 3) Feature selection and preprocessing\n",
        "# Use only numeric features, excluding identifiers and targets\n",
        "exclude_cols = {'date_id', TARGET, 'forward_returns', 'risk_free_rate'}\n",
        "num_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "feature_cols = [c for c in num_cols if c not in exclude_cols]\n",
        "LOGGER.info(f'Initial numeric feature count: {len(feature_cols)}')\n",
        "\n",
        "# Concatenate train+test in time order for leak-free lag/rolling creation (test follows train)\n",
        "DF = pd.concat([\n",
        "    train[feature_cols + (['date_id'] if 'date_id' in train.columns else [])],\n",
        "    test[feature_cols + (['date_id'] if 'date_id' in test.columns else [])]\n",
        "], axis=0, ignore_index=True)\n",
        "\n",
        "# Replace infs and fill base NaNs using train-only medians\n",
        "train_rows = train.shape[0]\n",
        "for col in feature_cols:\n",
        "    DF[col] = DF[col].replace([np.inf, -np.inf], np.nan)\n",
        "base_medians = train[feature_cols].median()\n",
        "DF[feature_cols] = DF[feature_cols].fillna(base_medians)\n",
        "\n",
        "# Light, fast feature engineering: 1-lag and 5-day rolling mean (shifted) per column\n",
        "lag_cols = []\n",
        "for col in feature_cols:\n",
        "    lag1 = f'{col}_lag1'\n",
        "    rmean5 = f'{col}_rmean5'\n",
        "    DF[lag1] = DF[col].shift(1)\n",
        "    DF[rmean5] = DF[col].rolling(window=5, min_periods=1).mean().shift(1)\n",
        "    lag_cols.extend([lag1, rmean5])\n",
        "\n",
        "# Fill lag feature NaNs using train-only medians to avoid leakage\n",
        "lag_medians = DF.iloc[:train_rows][lag_cols].median()\n",
        "DF[lag_cols] = DF[lag_cols].fillna(lag_medians)\n",
        "\n",
        "# Re-split into engineered train/test\n",
        "train_fe = DF.iloc[:train_rows].copy()\n",
        "test_fe  = DF.iloc[train_rows:].copy()\n",
        "\n",
        "# Restore target and date_id\n",
        "train_fe[TARGET] = train[TARGET].values\n",
        "if 'date_id' in train.columns:\n",
        "    train_fe['date_id'] = train['date_id'].values\n",
        "if 'date_id' in test.columns:\n",
        "    test_fe['date_id'] = test['date_id'].values\n",
        "\n",
        "# Final feature list\n",
        "features = [c for c in train_fe.columns if c not in ['date_id', TARGET]]\n",
        "LOGGER.info(f'Final features count: {len(features)}')\n",
        "\n",
        "# Quick EDA prints\n",
        "LOGGER.info('Basic EDA:')\n",
        "LOGGER.info(f\"Target mean/std: {train_fe[TARGET].mean():.6f} {train_fe[TARGET].std():.6f}\")\n",
        "missing_rate = train[feature_cols].isna().mean().mean()\n",
        "LOGGER.info(f'Average missing rate (pre-impute) over base features: {missing_rate:.4f}')\n",
        "\n",
        "# 4) Time-series CV: expanding window / walk-forward\n",
        "\n",
        "def expanding_walk_forward_splits(n_samples: int,\n",
        "                                  n_splits: int = 5,\n",
        "                                  min_train_ratio: float = 0.6,\n",
        "                                  val_size_ratio: float = 0.1,\n",
        "                                  min_train: int = 252,\n",
        "                                  min_val: int = 120):\n",
        "    min_train_size = max(int(n_samples * min_train_ratio), min_train)\n",
        "    val_size = max(int(n_samples * val_size_ratio), min_val)\n",
        "    if min_train_size + val_size >= n_samples:\n",
        "        # fallback to ensure at least one fold\n",
        "        min_train_size = max(min_train, n_samples - 2 * min_val)\n",
        "        val_size = min_val\n",
        "    starts = np.linspace(min_train_size, n_samples - val_size, num=n_splits, dtype=int)\n",
        "    seen = set()\n",
        "    for s in starts:\n",
        "        if s in seen:\n",
        "            continue\n",
        "        seen.add(s)\n",
        "        tr_idx = np.arange(0, s)\n",
        "        val_end = min(s + val_size, n_samples)\n",
        "        val_idx = np.arange(s, val_end)\n",
        "        if len(val_idx) > 0:\n",
        "            yield tr_idx, val_idx\n",
        "\n",
        "n_samples = train_fe.shape[0]\n",
        "splits = list(expanding_walk_forward_splits(n_samples, n_splits=5))\n",
        "LOGGER.info(f'CV folds: {len(splits)}')\n",
        "\n",
        "# 5) Train LightGBM models on each fold\n",
        "lgb_params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'rmse',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'learning_rate': 0.02,\n",
        "    'num_leaves': 64,\n",
        "    'max_depth': -1,\n",
        "    'min_data_in_leaf': 50,\n",
        "    'feature_fraction': 0.7,\n",
        "    'bagging_fraction': 0.8,\n",
        "    'bagging_freq': 5,\n",
        "    'seed': SEED,\n",
        "    'verbosity': -1,\n",
        "    'num_threads': -1,\n",
        "}\n",
        "\n",
        "models = []\n",
        "val_scores = []\n",
        "feature_importance_df = pd.DataFrame()\n",
        "\n",
        "for fold, (tr_idx, val_idx) in enumerate(splits):\n",
        "    X_tr = train_fe.iloc[tr_idx][features]\n",
        "    y_tr = train_fe.iloc[tr_idx][TARGET]\n",
        "    X_val = train_fe.iloc[val_idx][features]\n",
        "    y_val = train_fe.iloc[val_idx][TARGET]\n",
        "\n",
        "    LOGGER.info(f'Fold {fold+1}/{len(splits)} — train {len(tr_idx)} val {len(val_idx)}')\n",
        "    dtrain = lgb.Dataset(X_tr, label=y_tr)\n",
        "    dvalid = lgb.Dataset(X_val, label=y_val)\n",
        "\n",
        "    bst = lgb.train(\n",
        "        params=lgb_params,\n",
        "        train_set=dtrain,\n",
        "        num_boost_round=2000,\n",
        "        valid_sets=[dtrain, dvalid],\n",
        "        valid_names=['train', 'valid'],\n",
        "        early_stopping_rounds=200,\n",
        "        verbose_eval=200,\n",
        "    )\n",
        "\n",
        "    models.append(bst)\n",
        "\n",
        "    val_pred = bst.predict(X_val, num_iteration=bst.best_iteration)\n",
        "    rmse = mean_squared_error(y_val, val_pred, squared=False)\n",
        "    LOGGER.info(f'Fold {fold+1} RMSE: {rmse:.6f}')\n",
        "    val_scores.append(rmse)\n",
        "\n",
        "    fi = pd.DataFrame({\n",
        "        'feature': features,\n",
        "        'importance': bst.feature_importance(importance_type='gain'),\n",
        "        'fold': fold,\n",
        "    })\n",
        "    feature_importance_df = pd.concat([feature_importance_df, fi], axis=0)\n",
        "\n",
        "    del X_tr, y_tr, X_val, y_val, dtrain, dvalid\n",
        "    gc.collect()\n",
        "\n",
        "LOGGER.info(f\"CV RMSE mean: {float(np.mean(val_scores)):.6f}\")\n",
        "LOGGER.info(f\"CV RMSE std : {float(np.std(val_scores)):.6f}\")\n",
        "\n",
        "# 6) OOF predictions for diagnostics/backtest\n",
        "oof = np.zeros(n_samples, dtype=float)\n",
        "counts = np.zeros(n_samples, dtype=float)\n",
        "for fold, (tr_idx, val_idx) in enumerate(splits):\n",
        "    bst = models[fold]\n",
        "    oof[val_idx] += bst.predict(train_fe.iloc[val_idx][features], num_iteration=bst.best_iteration)\n",
        "    counts[val_idx] += 1\n",
        "\n",
        "mask = counts > 0\n",
        "oof[mask] /= counts[mask]\n",
        "train_fe['pred'] = oof\n",
        "\n",
        "# Feature importances (mean over folds)\n",
        "fi_mean = (feature_importance_df.groupby('feature')['importance']\n",
        "           .mean().sort_values(ascending=False))\n",
        "LOGGER.info('Top 20 features by average gain:')\n",
        "LOGGER.info(f\"\\n{fi_mean.head(20)}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "fi_mean.head(20).sort_values().plot(kind='barh')\n",
        "plt.title('Top 20 feature importances (avg gain)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 7) Simple volatility-aware mapping from predictions to allocation in [0, 2]\n",
        "# Estimate rolling prediction volatility to scale signals\n",
        "pred_sigma = pd.Series(train_fe['pred']).rolling(window=20, min_periods=5).std()\n",
        "pred_sigma = pred_sigma.fillna(pred_sigma.iloc[5:25].median() if pred_sigma.notna().any() else 1.0)\n",
        "\n",
        "risk_k = 0.8  # aggressiveness; tune in walk-forward if time allows\n",
        "alloc_oof = 1.0 + risk_k * (train_fe['pred'] / (pred_sigma.replace(0, np.nan).fillna(1e-6)))\n",
        "alloc_oof = alloc_oof.clip(0.0, 2.0)\n",
        "train_fe['alloc'] = alloc_oof\n",
        "\n",
        "# Enforce vol cap: realized strategy vol <= 1.2 * market vol (rolling)\n",
        "if realized_returns is not None:\n",
        "    train_fe['realized_returns'] = realized_returns.values\n",
        "    strat_ret_raw = train_fe['alloc'] * train_fe['realized_returns']\n",
        "    strat_vol_180 = strat_ret_raw.rolling(180, min_periods=30).std().fillna(strat_ret_raw.std())\n",
        "    market_vol_180 = train_fe['realized_returns'].rolling(180, min_periods=30).std().fillna(train_fe['realized_returns'].std())\n",
        "\n",
        "    scale = (1.2 * market_vol_180) / (strat_vol_180.replace(0, np.nan).fillna(1e-6))\n",
        "    scale = scale.clip(0.0, 2.0)\n",
        "    alloc_scaled = 1.0 + (train_fe['alloc'] - 1.0) * scale\n",
        "    train_fe['alloc_scaled'] = alloc_scaled.clip(0.0, 2.0)\n",
        "\n",
        "    # Simple transaction cost model: one-way cost on changes in allocation\n",
        "    tc = CONFIG.get('transaction_cost_bps', 0.0) / 10000.0\n",
        "    alloc_change_raw = train_fe['alloc'].diff().abs().fillna(0.0)\n",
        "    alloc_change_scaled = train_fe['alloc_scaled'].diff().abs().fillna(0.0)\n",
        "    tc_raw = tc * alloc_change_raw\n",
        "    tc_scaled = tc * alloc_change_scaled\n",
        "\n",
        "    # Backtest diagnostics (after costs)\n",
        "    train_fe['strat_ret_raw'] = strat_ret_raw - tc_raw\n",
        "    train_fe['strat_ret_scaled'] = (train_fe['alloc_scaled'] * train_fe['realized_returns']) - tc_scaled\n",
        "\n",
        "    train_fe['cum_sp500'] = (1.0 + train_fe['realized_returns']).cumprod()\n",
        "    train_fe['cum_raw']   = (1.0 + train_fe['strat_ret_raw']).cumprod()\n",
        "    train_fe['cum_scaled']= (1.0 + train_fe['strat_ret_scaled']).cumprod()\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    x_axis = train_fe['date_id'] if 'date_id' in train_fe.columns else np.arange(len(train_fe))\n",
        "    plt.plot(x_axis, train_fe['cum_sp500'], label='Market (buy-hold)')\n",
        "    plt.plot(x_axis, train_fe['cum_raw'], label='Strategy (raw)')\n",
        "    plt.plot(x_axis, train_fe['cum_scaled'], label='Strategy (vol scaled)')\n",
        "    plt.legend(); plt.title('Cumulative performance (toy backtest)'); plt.tight_layout(); plt.show()\n",
        "\n",
        "    def ann_sharpe(returns: pd.Series, days_per_year: int = 252):\n",
        "        mu = returns.mean() * days_per_year\n",
        "        sd = returns.std() * np.sqrt(days_per_year)\n",
        "        return float(mu / (sd + 1e-9))\n",
        "\n",
        "    LOGGER.info(f\"Ann Sharpe raw   (toy): {ann_sharpe(train_fe['strat_ret_raw'].fillna(0)):.4f}\")\n",
        "    LOGGER.info(f\"Ann Sharpe scaled(toy): {ann_sharpe(train_fe['strat_ret_scaled'].fillna(0)):.4f}\")\n",
        "    LOGGER.info(f\"Ann Sharpe market      : {ann_sharpe(train_fe['realized_returns'].fillna(0)):.4f}\")\n",
        "else:\n",
        "    LOGGER.warning('Skipping backtest: realized forward returns not available in train.')\n",
        "\n",
        "# 8) Train final ensemble on full train and predict test\n",
        "X_full = train_fe[features]\n",
        "y_full = train_fe[TARGET]\n",
        "\n",
        "avg_best_iter = int(np.clip(np.mean([m.best_iteration for m in models]), 200, 2000)) if len(models) else 1000\n",
        "LOGGER.info(f'Using avg_best_iter: {avg_best_iter}')\n",
        "\n",
        "final_models = []\n",
        "N_FINAL = 3  # small ensemble for stability\n",
        "for i in range(N_FINAL):\n",
        "    params = lgb_params.copy()\n",
        "    params['seed'] = SEED + 13 * i\n",
        "    dtrain = lgb.Dataset(X_full, label=y_full)\n",
        "    bst = lgb.train(params, dtrain, num_boost_round=avg_best_iter, verbose_eval=False)\n",
        "    final_models.append(bst)\n",
        "    del dtrain\n",
        "\n",
        "def rank_normalize(arr: np.ndarray) -> np.ndarray:\n",
        "    n = len(arr)\n",
        "    if n <= 1:\n",
        "        return np.zeros_like(arr, dtype=float)\n",
        "    ranks = np.argsort(np.argsort(arr))\n",
        "    return ranks.astype(float) / max(n - 1, 1)\n",
        "\n",
        "# Predict test with rank-based ensembling (often more robust for Sharpe-like metrics)\n",
        "X_test = test_fe[features]\n",
        "preds_list = []\n",
        "for bst in final_models:\n",
        "    preds_list.append(bst.predict(X_test, num_iteration=bst.best_iteration))\n",
        "\n",
        "# Average of ranks (0..1), then center roughly around 0 by subtracting 0.5 for mapping\n",
        "ranked_preds = np.stack([rank_normalize(p) for p in preds_list], axis=1).mean(axis=1)\n",
        "preds_test = ranked_preds - 0.5\n",
        "\n",
        "# Allocation mapping in [0, 2]\n",
        "# Use sigma estimated from recent prediction volatility on train as a proxy\n",
        "pred_sigma_train = pd.Series(train_fe['pred']).rolling(window=20, min_periods=5).std()\n",
        "if pred_sigma_train.notna().any():\n",
        "    sigma_est = float(pred_sigma_train.iloc[-50:].median()) if pred_sigma_train.iloc[-50:].notna().any() else float(pred_sigma_train.dropna().median())\n",
        "else:\n",
        "    sigma_est = float(train_fe['pred'].std() if 'pred' in train_fe else 1.0)\n",
        "\n",
        "k = 0.8  # same aggressiveness factor used above\n",
        "alloc_test = 1.0 + k * (preds_test / (sigma_est + 1e-9))\n",
        "alloc_test = np.clip(alloc_test, 0.0, 2.0)\n",
        "\n",
        "# Apply a global downscale if recent historical strategy vol would breach cap\n",
        "if realized_returns is not None:\n",
        "    hist_window = min(len(train_fe), 180)\n",
        "    hist_strat_vol = (train_fe['alloc'].iloc[-hist_window:] * train_fe['realized_returns'].iloc[-hist_window:]).std()\n",
        "    hist_mkt_vol   = train_fe['realized_returns'].iloc[-hist_window:].std()\n",
        "    scale_global = min(1.0, (1.2 * hist_mkt_vol) / (hist_strat_vol + 1e-9)) if hist_strat_vol > 0 else 1.0\n",
        "    alloc_test = 1.0 + (alloc_test - 1.0) * scale_global\n",
        "    alloc_test = np.clip(alloc_test, 0.0, 2.0)\n",
        "\n",
        "# Prepare submission\n",
        "submission = pd.DataFrame({\n",
        "    'date_id': test_fe['date_id'].values if 'date_id' in test_fe.columns else np.arange(len(test_fe)),\n",
        "    'allocation': alloc_test.astype(float)\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "LOGGER.info(f\"Wrote submission.csv with {submission.shape[0]} rows\")\n",
        "LOGGER.debug(f\"Submission head:\\n{submission.head()}\")\n",
        "\n",
        "# Save artifacts\n",
        "try:\n",
        "    import joblib\n",
        "    joblib.dump(final_models, 'final_lgb_models.pkl')\n",
        "    LOGGER.info('Saved final_lgb_models.pkl')\n",
        "except Exception as e:\n",
        "    LOGGER.warning(f'Model save skipped: {e}')\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "LOGGER.info(f'Total runtime: {elapsed/60:.1f} min')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Production configuration, logging, and utilities ===\n",
        "import logging, json, random, platform\n",
        "\n",
        "def get_logger(name: str = 'hull_prod', level: int = logging.INFO) -> logging.Logger:\n",
        "    logger = logging.getLogger(name)\n",
        "    if not logger.handlers:\n",
        "        logger.setLevel(level)\n",
        "        ch = logging.StreamHandler()\n",
        "        ch.setLevel(level)\n",
        "        fmt = logging.Formatter('[%(asctime)s] %(levelname)s:%(name)s: %(message)s')\n",
        "        ch.setFormatter(fmt)\n",
        "        logger.addHandler(ch)\n",
        "    return logger\n",
        "\n",
        "LOGGER = get_logger()\n",
        "\n",
        "CONFIG = {\n",
        "    'random_seed': 42,\n",
        "    'oof_pred_vol_halflife': 10,     # days for EWMA pred volatility\n",
        "    'realized_vol_halflife': 60,     # days for EWMA realized volatility\n",
        "    'vol_cap_multiple': 1.2,         # cap strategy vol to X * market vol\n",
        "    'risk_k_grid': [0.4, 0.6, 0.8, 1.0, 1.2],\n",
        "    'neutral_band_grid': [0.0, 0.05, 0.10, 0.15],  # deadband in z-score units\n",
        "    'artifacts_dir': 'artifacts',\n",
        "'transaction_cost_bps': 1.0,   # one-way cost in basis points, applied on allocation change\n",
        "}\n",
        "\n",
        "# Deterministic seeds\n",
        "os.environ['PYTHONHASHSEED'] = str(CONFIG['random_seed'])\n",
        "random.seed(CONFIG['random_seed'])\n",
        "np.random.seed(CONFIG['random_seed'])\n",
        "\n",
        "try:\n",
        "    import lightgbm as _lgb\n",
        "    _ = _lgb.__version__\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "LOGGER.info('Environment info:')\n",
        "LOGGER.info(f\"Python: {platform.python_version()}\")\n",
        "LOGGER.info(f\"NumPy: {np.__version__}, Pandas: {pd.__version__}\")\n",
        "try:\n",
        "    LOGGER.info(f\"LightGBM: {lgb.__version__}\")\n",
        "except Exception:\n",
        "    LOGGER.info('LightGBM version: N/A')\n",
        "\n",
        "# Helpers\n",
        "from pathlib import Path\n",
        "\n",
        "def ensure_dir(path: str):\n",
        "    Path(path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ensure_dir(CONFIG['artifacts_dir'])\n",
        "LOGGER.info('Production utilities configured.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Date-based CV helper and validation checks ===\n",
        "from typing import Iterator, Tuple\n",
        "\n",
        "def assert_required_columns(df: pd.DataFrame, cols: list):\n",
        "    missing = [c for c in cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns: {missing}\")\n",
        "\n",
        "# Ensure time order and integer monotonicity for date_id if present\n",
        "if 'date_id' in train.columns:\n",
        "    assert train['date_id'].is_monotonic_increasing, 'train.date_id must be sorted ascending'\n",
        "if 'date_id' in test.columns:\n",
        "    assert test['date_id'].is_monotonic_increasing, 'test.date_id must be sorted ascending'\n",
        "\n",
        "assert_required_columns(train_fe, features + [TARGET])\n",
        "\n",
        "# Optionally allow date-aware split sizes (fixed by unique dates rather than rows)\n",
        "def walk_forward_by_dates(df: pd.DataFrame,\n",
        "                          date_col: str,\n",
        "                          n_splits: int = 5,\n",
        "                          min_train_days: int = 252,\n",
        "                          val_days: int = 120) -> Iterator[Tuple[np.ndarray, np.ndarray]]:\n",
        "    dates = df[date_col].values\n",
        "    unique_dates = np.unique(dates)\n",
        "    if len(unique_dates) < (min_train_days + val_days + 1):\n",
        "        # fallback to row-based splits already built\n",
        "        for s in splits:\n",
        "            yield s\n",
        "        return\n",
        "    anchors = np.linspace(min_train_days, len(unique_dates) - val_days, n_splits, dtype=int)\n",
        "    for a in anchors:\n",
        "        train_last_date = unique_dates[a - 1]\n",
        "        val_last_date = unique_dates[min(a + val_days - 1, len(unique_dates) - 1)]\n",
        "        tr_idx = np.where(dates <= train_last_date)[0]\n",
        "        val_idx = np.where((dates > train_last_date) & (dates <= val_last_date))[0]\n",
        "        if len(val_idx) > 0:\n",
        "            yield tr_idx, val_idx\n",
        "\n",
        "# If date_id exists, we can produce alternative date-based splits for diagnostics\n",
        "if 'date_id' in train_fe.columns:\n",
        "    date_splits = list(walk_forward_by_dates(train_fe, 'date_id'))\n",
        "    LOGGER.info(f\"Date-based splits prepared: {len(date_splits)} folds\")\n",
        "else:\n",
        "    date_splits = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === EWMA volatility functions and risk calibration ===\n",
        "\n",
        "def ewma_std(series: pd.Series, halflife: int) -> pd.Series:\n",
        "    if series.isna().all():\n",
        "        return pd.Series(index=series.index, dtype=float)\n",
        "    # Use ewm variance then sqrt\n",
        "    v = series.ewm(halflife=halflife, min_periods=max(5, halflife//2)).var()\n",
        "    return np.sqrt(v).fillna(method='bfill').fillna(method='ffill')\n",
        "\n",
        "# Calibrate risk parameters using OOF predictions and realized returns\n",
        "# Grid search over k (aggressiveness) and neutral band (dead zone around 0 signal)\n",
        "\n",
        "def calibrate_k_and_band(oof_pred: pd.Series,\n",
        "                         realized: pd.Series,\n",
        "                         pred_halflife: int,\n",
        "                         realized_halflife: int,\n",
        "                         k_grid: list,\n",
        "                         band_grid: list,\n",
        "                         vol_cap_multiple: float = 1.2,\n",
        "                         annualization: int = 252) -> dict:\n",
        "    assert len(oof_pred) == len(realized)\n",
        "    oof_pred = oof_pred.astype(float)\n",
        "    realized = realized.astype(float)\n",
        "\n",
        "    pred_sigma = ewma_std(oof_pred, pred_halflife)\n",
        "    mkt_vol = ewma_std(realized, realized_halflife)\n",
        "\n",
        "    best = {'score': -np.inf, 'k': None, 'band': None}\n",
        "\n",
        "    for k in k_grid:\n",
        "        # z-score like signal\n",
        "        z = oof_pred / (pred_sigma.replace(0, np.nan).fillna(1e-6))\n",
        "        for band in band_grid:\n",
        "            z_band = z.where(z.abs() >= band, 0.0)\n",
        "            alloc = (1.0 + k * z_band).clip(0.0, 2.0)\n",
        "            strat_ret = alloc * realized\n",
        "            strat_vol = ewma_std(strat_ret, realized_halflife)\n",
        "            cap = (vol_cap_multiple * mkt_vol) / (strat_vol.replace(0, np.nan).fillna(1e-6))\n",
        "            cap = cap.clip(0.0, 2.0)\n",
        "            alloc_scaled = (1.0 + (alloc - 1.0) * cap).clip(0.0, 2.0)\n",
        "            strat_ret_scaled = alloc_scaled * realized\n",
        "            # Sharpe-like objective\n",
        "            mu = strat_ret_scaled.mean() * annualization\n",
        "            sd = strat_ret_scaled.std() * np.sqrt(annualization)\n",
        "            score = (mu / (sd + 1e-9)) if sd > 0 else -np.inf\n",
        "            if score > best['score']:\n",
        "                best = {'score': float(score), 'k': float(k), 'band': float(band)}\n",
        "    return best\n",
        "\n",
        "if 'pred' in train_fe.columns and realized_returns is not None:\n",
        "    best_risk = calibrate_k_and_band(\n",
        "        oof_pred=train_fe['pred'],\n",
        "        realized=train_fe['realized_returns'] if 'realized_returns' in train_fe.columns else realized_returns,\n",
        "        pred_halflife=CONFIG['oof_pred_vol_halflife'],\n",
        "        realized_halflife=CONFIG['realized_vol_halflife'],\n",
        "        k_grid=CONFIG['risk_k_grid'],\n",
        "        band_grid=CONFIG['neutral_band_grid'],\n",
        "        vol_cap_multiple=CONFIG['vol_cap_multiple'],\n",
        "    )\n",
        "    LOGGER.info(f\"Calibrated risk params: k={best_risk['k']}, band={best_risk['band']}, score={best_risk['score']:.4f}\")\n",
        "\n",
        "    # Recompute allocation series using calibrated params\n",
        "    pred_sigma = ewma_std(train_fe['pred'], CONFIG['oof_pred_vol_halflife'])\n",
        "    z = train_fe['pred'] / (pred_sigma.replace(0, np.nan).fillna(1e-6))\n",
        "    z_band = z.where(z.abs() >= best_risk['band'], 0.0)\n",
        "    alloc_calib = (1.0 + best_risk['k'] * z_band).clip(0.0, 2.0)\n",
        "    mkt_vol = ewma_std(train_fe['realized_returns'], CONFIG['realized_vol_halflife'])\n",
        "    strat_vol = ewma_std(alloc_calib * train_fe['realized_returns'], CONFIG['realized_vol_halflife'])\n",
        "    cap = (CONFIG['vol_cap_multiple'] * mkt_vol) / (strat_vol.replace(0, np.nan).fillna(1e-6))\n",
        "    cap = cap.clip(0.0, 2.0)\n",
        "    train_fe['alloc_calibrated'] = (1.0 + (alloc_calib - 1.0) * cap).clip(0.0, 2.0)\n",
        "\n",
        "    # Apply transaction costs on calibrated series\n",
        "    tc = CONFIG.get('transaction_cost_bps', 0.0) / 10000.0\n",
        "    alloc_change_cal = train_fe['alloc_calibrated'].diff().abs().fillna(0.0)\n",
        "    tc_cal = tc * alloc_change_cal\n",
        "\n",
        "    # Diagnostics\n",
        "    strat_cal = (train_fe['alloc_calibrated'] * train_fe['realized_returns']) - tc_cal\n",
        "    cum_cal = (1.0 + strat_cal).cumprod()\n",
        "    cum_mkt = (1.0 + train_fe['realized_returns']).cumprod()\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    x_axis = train_fe['date_id'] if 'date_id' in train_fe.columns else np.arange(len(train_fe))\n",
        "    plt.plot(x_axis, cum_mkt, label='Market (buy-hold)')\n",
        "    plt.plot(x_axis, cum_cal, label='Strategy (calibrated)')\n",
        "    plt.legend(); plt.title('Cumulative performance — calibrated'); plt.tight_layout(); plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Apply calibrated risk to TEST predictions (if available) and save artifacts ===\n",
        "\n",
        "# If we calibrated best_risk, we also map test predictions with the same parameters.\n",
        "# We reuse test predictions already computed (ranked_preds -> preds_test) and\n",
        "# estimate sigma from recent train OOF prediction EWMA.\n",
        "\n",
        "artifacts = {}\n",
        "\n",
        "if 'pred' in train_fe.columns:\n",
        "    pred_sigma_train = ewma_std(train_fe['pred'], CONFIG['oof_pred_vol_halflife'])\n",
        "    sigma_est = float(pred_sigma_train.iloc[-50:].median()) if pred_sigma_train.notna().any() else float(train_fe['pred'].std())\n",
        "else:\n",
        "    sigma_est = float(train_fe['pred'].std()) if 'pred' in train_fe else 1.0\n",
        "\n",
        "# Prefer calibrated params if present\n",
        "k_use = best_risk['k'] if 'best_risk' in globals() and best_risk['k'] is not None else 0.8\n",
        "band_use = best_risk['band'] if 'best_risk' in globals() and best_risk['band'] is not None else 0.0\n",
        "\n",
        "# Center preds_test (already centered earlier). Apply band and scaling.\n",
        "z_test = preds_test / (sigma_est + 1e-9)\n",
        "z_test_band = np.where(np.abs(z_test) >= band_use, z_test, 0.0)\n",
        "alloc_test_cal = 1.0 + k_use * z_test_band\n",
        "alloc_test_cal = np.clip(alloc_test_cal, 0.0, 2.0)\n",
        "\n",
        "# Optional global downscale using recent historical cap (after costs)\n",
        "if realized_returns is not None and 'alloc_calibrated' in train_fe.columns:\n",
        "    hist_window = min(len(train_fe), 180)\n",
        "    tc = CONFIG.get('transaction_cost_bps', 0.0) / 10000.0\n",
        "    alloc_change_hist = train_fe['alloc_calibrated'].iloc[-hist_window:].diff().abs().fillna(0.0)\n",
        "    tc_hist = tc * alloc_change_hist\n",
        "    strat_hist = (train_fe['alloc_calibrated'].iloc[-hist_window:] * train_fe['realized_returns'].iloc[-hist_window:]) - tc_hist\n",
        "    hist_strat_vol = float(ewma_std(strat_hist, CONFIG['realized_vol_halflife']).iloc[-1]) if len(strat_hist) else strat_hist.std()\n",
        "    hist_mkt_vol   = float(ewma_std(train_fe['realized_returns'].iloc[-hist_window:], CONFIG['realized_vol_halflife']).iloc[-1])\n",
        "    scale_global = min(1.0, (CONFIG['vol_cap_multiple'] * hist_mkt_vol) / (hist_strat_vol + 1e-9)) if hist_strat_vol > 0 else 1.0\n",
        "    alloc_test_cal = 1.0 + (alloc_test_cal - 1.0) * scale_global\n",
        "    alloc_test_cal = np.clip(alloc_test_cal, 0.0, 2.0)\n",
        "\n",
        "# Overwrite submission with calibrated allocations (if available)\n",
        "submission_cal = pd.DataFrame({\n",
        "    'date_id': test_fe['date_id'].values if 'date_id' in test_fe.columns else np.arange(len(test_fe)),\n",
        "    'allocation': alloc_test_cal.astype(float)\n",
        "})\n",
        "submission_cal.to_csv('submission.csv', index=False)\n",
        "LOGGER.info('Overwrote submission.csv with calibrated allocations')\n",
        "\n",
        "# Save artifacts for reproducibility\n",
        "ensure_dir(CONFIG['artifacts_dir'])\n",
        "\n",
        "# CV metrics\n",
        "cv_metrics = {\n",
        "    'cv_rmse_mean': float(np.mean(val_scores)) if len(val_scores) else None,\n",
        "    'cv_rmse_std': float(np.std(val_scores)) if len(val_scores) else None,\n",
        "    'n_models': int(len(models)),\n",
        "}\n",
        "with open(os.path.join(CONFIG['artifacts_dir'], 'cv_metrics.json'), 'w') as f:\n",
        "    json.dump(cv_metrics, f, indent=2)\n",
        "\n",
        "# OOF predictions\n",
        "if 'pred' in train_fe.columns:\n",
        "    train_fe[['date_id', TARGET, 'pred']].to_csv(os.path.join(CONFIG['artifacts_dir'], 'oof_predictions.csv'), index=False)\n",
        "\n",
        "# Feature importances\n",
        "if not feature_importance_df.empty:\n",
        "    fi_mean.reset_index().rename(columns={'index':'feature','importance':'importance_mean'}) \\\n",
        "        .to_csv(os.path.join(CONFIG['artifacts_dir'], 'feature_importances.csv'), index=False)\n",
        "\n",
        "# Metadata\n",
        "metadata = {\n",
        "    'config': CONFIG,\n",
        "    'avg_best_iter': int(avg_best_iter),\n",
        "    'seed': int(SEED),\n",
        "}\n",
        "with open(os.path.join(CONFIG['artifacts_dir'], 'metadata.json'), 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "LOGGER.info('Artifacts saved to artifacts/.')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
